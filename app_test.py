import streamlit as st
from google import genai
from google.genai import types

# 1. ç”»é¢ã®è¨­å®š
st.set_page_config(page_title="ã“ã©ã‚‚è³ªå•ç®±", page_icon="ğŸ£")
st.title("ğŸ£ ã“ã©ã‚‚è³ªå•ç®±")
st.caption("3ã•ã„ã€œ10ã•ã„ã®ã¿ã‚“ãªã® ãã‚‚ã‚“ã« ã“ãŸãˆã‚‹ã‚ˆï¼")

# 2. APIã‚­ãƒ¼ã®è¨­å®š
api_key = st.sidebar.text_input("Gemini API Key", type="password")

if api_key:
    try:
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        client = genai.Client(api_key=api_key)
        
        # 3. ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        SYSTEM_PROMPT = """
        ã‚ãªãŸã¯ã€Œã“ã©ã‚‚è³ªå•ç®±ã€ã®å„ªã—ã„å…ˆç”Ÿã§ã™ã€‚
        - 3æ­³ã‹ã‚‰10æ­³ã®å­ä¾›ãŒç†è§£ã§ãã‚‹è¨€è‘‰ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
        - æ¼¢å­—ã«ã¯ï¼ˆï¼‰ã§èª­ã¿ãŒãªã‚’æŒ¯ã‚‹ã‹ã€å¹³ä»®åã‚’å¤šã‚ã«ã—ã¦ãã ã•ã„ã€‚
        - å›ç­”ã¯çŸ­ãã€3æ–‡ä»¥å†…ã§ç­”ãˆã¦ãã ã•ã„ã€‚
        - ä¾‹ãˆè©±ã‚’ä½¿ã„ã€ãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹ã‚ˆã†ãªæ•™ãˆæ–¹ã‚’ã—ã¦ãã ã•ã„ã€‚
        - å±é™ºãªã“ã¨ã‚„æ‚ªã„ã“ã¨ã«ã¤ã„ã¦ã¯ã€å„ªã—ãè«­ã—ã¦ãã ã•ã„ã€‚
        """

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # å±¥æ­´ã®è¡¨ç¤º
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # 4. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›
        if prompt := st.chat_input("ãªã«ãŒ ã—ã‚ŠãŸã„ï¼Ÿ"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # Geminiã‹ã‚‰ã®å›ç­”ã‚’ç”Ÿæˆ
            with st.chat_message("assistant"):
                try:
                    config = types.GenerateContentConfig(system_instruction=SYSTEM_PROMPT)
                    
                    # ã€é‡è¦ã€‘404å¯¾ç­–ï¼šãƒ¢ãƒ‡ãƒ«åã‚’ãƒ•ãƒ«ãƒ‘ã‚¹ã€Œmodels/gemini-2.0-flashã€ã§æŒ‡å®š
                    # ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒãƒ¢ãƒ‡ãƒ«ã‚’è¦‹å¤±ã†ã®ã‚’é˜²ãã¾ã™
                    response = client.models.generate_content(
                        model="models/gemini-2.0-flash", 
                        config=config,
                        contents=prompt
                    )
                    
                    if response.text:
                        st.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                    else:
                        st.error("AIãŒå›ç­”ã‚’ä½œã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                
                except Exception as e:
                    error_str = str(e)
                    if "429" in error_str:
                        st.error("æ··ã¿åˆã£ã¦ã„ã¾ã™ã€‚1åˆ†å¾…ã£ã¦ãã ã•ã„ã€‚")
                    elif "404" in error_str:
                        # ã¾ã 404ãŒå‡ºã‚‹å ´åˆã®äºˆå‚™ï¼šåˆ¥åã§å†è©¦è¡Œ
                        st.error("ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åå‰ã‚’ models/gemini-1.5-flash ã«å¤‰ãˆã¦è©¦ã—ã¾ã™...")
                        try:
                            response = client.models.generate_content(
                                model="models/gemini-1.5-flash", 
                                config=config,
                                contents=prompt
                            )
                            st.markdown(response.text)
                            st.session_state.messages.append({"role": "assistant", "content": response.text})
                        except:
                            st.error("ã‚„ã¯ã‚Šæ¥ç¶šã§ãã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    else:
                        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_str}")
                    
    except Exception as init_error:
        st.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {init_error}")
else:
    st.info("â† å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã« APIã‚­ãƒ¼ã‚’ã„ã‚Œã¦ã­ï¼")
